# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Repository Overview

This is a **monorepo development environment** for the Conestack organization, which develops a collection of interrelated Python packages. The repository uses **mxdev/mxmake** to manage development of 50+ packages simultaneously.

### Package Families

The codebase consists of three main package families:

1. **node.*** - Tree/node data structure libraries (foundation layer)
   - `node` - Core tree data structures using ordered dictionaries
   - `node.ext.directory`, `node.ext.fs`, `node.ext.ldap`, `node.ext.ugm`, `node.ext.yaml`, `node.ext.zodb` - Extensions for various backends

2. **yafowil.*** - Form library and widgets
   - `yafowil` - Yet Another Form Widget Library (core)
   - `yafowil.bootstrap` - Bootstrap integration
   - `yafowil.widget.*` - Widget extensions (ace, array, autocomplete, chosen, color, cron, datetime, dict, dynatree, image, location, multiselect, richtext, select2, slider, tiptap, wysihtml5)

3. **cone.*** - Web application framework built on Pyramid
   - `cone.app` - Main web application framework
   - `cone.tile` - Tile composition system
   - `cone.ugm` - User/Group management
   - `cone.ldap`, `cone.sql`, `cone.zodb` - Backend integrations
   - `cone.calendar`, `cone.charts`, `cone.fileupload`, `cone.firebase`, `cone.maps`, `cone.tokens` - Feature packages

**Supporting packages:** `odict`, `plumber`, `webresource`, `treibstoff`, `mxdev`, `mxmake`

### Directory Structure

- `sources/` - All package source code (checked out from individual Git repos via mxdev)
- `mx.ini` - Configuration file defining all package repositories and build settings
- `Makefile` - Generated by mxmake; provides build/test/install targets
- `venv/` - Python virtual environment
- `openldap/` - Locally built OpenLDAP server (required for LDAP-related tests)
- `.mxmake/` - Build system artifacts and generated scripts

**Important:** Packages in `sources/` may contain their own nested mxmake setup (with their own `sources/`, `venv/`, etc.) if they were developed standalone. When working from the root conestack directory, **ignore these nested structures** - they are for standalone development of individual packages. Only the root-level directories matter for monorepo development.

## Common Commands

### Initial Setup

```bash
# Install system dependencies (Debian/Ubuntu)
make system-dependencies

# Full project install (creates venv, checks out sources, installs packages)
make install

# Or step by step:
make mxenv        # Create virtual environment
make sources      # Checkout all source repositories
make mxfiles      # Generate dependency files
make packages     # Install all packages
```

### Testing

```bash
# Run all tests across all packages
make test

# Run coverage
make coverage
```

**pytest** is used as the test runner for all packages defined in mx.ini. Tests requiring LDAP functionality need the OpenLDAP installation (built via `make openldap`).

**Testing styles vary by package**:
- Most packages use **unittest.TestCase** with **zope.testlayer** fixtures
- **zope.pytestlayer** provides pytest compatibility for zope testlayers
- Some packages use pytest-style tests with pytest fixtures
- **Never mix styles within a single package**

### Building Documentation

```bash
# Build documentation (uses Sphinx)
cd docs
make html
```

### Cleanup

```bash
# Clean build artifacts (keeps sources)
make clean

# Remove sources directory too
make purge

# Or clean specific components
make mxenv-clean      # Remove virtual environment
make packages-clean   # Uninstall packages
make sources-purge    # Remove checked out sources
```

### Working with Sources

```bash
# Re-checkout sources after mx.ini changes
make sources-dirty
make sources

# Reinstall packages after source changes
make packages-dirty
make packages
```

## Build System Architecture

This project uses **mxmake** (managed multi-repository make) with **mxdev** (managed development tool):

- **mx.ini** defines all repositories, branches, and build configuration
- **mxdev** checks out sources from GitHub and generates requirements files
- **mxmake** generates the Makefile with orchestrated build targets
- Virtual environment uses **uv** as the package installer (faster than pip)

### Environment Variables

The test runner sets these environment variables (defined in mx.ini):

- `TESTRUN_MARKER=1`
- `LDAP_ADD_BIN=openldap/bin/ldapadd`
- `LDAP_DELETE_BIN=openldap/bin/ldapdelete`
- `SLAPD_BIN=openldap/libexec/slapd`
- `SLAPD_URIS=ldap://127.0.0.1:12345`

## Package Structure Convention

Most packages follow a consistent structure:

```
package-name/
├── src/
│   └── namespace/
│       └── package/
│           ├── __init__.py
│           ├── (implementation files)
│           └── tests/
├── pyproject.toml
└── README.rst
```

Most packages use namespace packages (e.g., `cone.app` has code in `src/cone/app/`).

## Python Version

Minimum Python version: **3.10** (configured in Makefile)
For current Python version see `.python-version`

## Working with Individual Packages

Each package in `sources/` is its own Git repository. To work on a specific package:

1. Changes made in `sources/package-name/` affect that package's repository
2. Use Git commands inside the specific package directory
3. The package is installed in development mode (editable install)
4. The root mx.ini defines which branch each package uses

## Key Configuration Files

- **mx.ini** - Package repository configuration, build settings, test paths
- **Makefile** - Generated build orchestration (Generated, only edited settings are kept)

## Development Guidelines

### General Workflow

- Every change, improvement, refactoring follows a detailed implementation plan
- When working on tests, never modify production code
- When production code is not covered by tests, add tests first
- When fixing bugs or adding features, update/extend tests in the same workflow
- Do not be too verbose (you're an LLM though).
- Do not hesitate to ask.

### Code Quality Standards

**Simplicity Rules**:
- The simplest solution that could possibly work
- YAGNI - implement only what's needed now
- Avoid premature optimization
- Delete dead code immediately

**Clarity Requirements**:
- Names should reveal intent
- Functions should do one thing
- Avoid clever code - optimize for readability
- Make dependencies explicit
- Fail fast and loud with clear error messages

**Refactoring Triggers** - Refactor when you see:
- Duplication (Rule of Three - refactor on third copy)
- Long methods (>20 lines is suspicious)
- Too many parameters (>3 is a smell)
- Comments explaining what code does (code should be self-documenting)
- Nested conditionals (extract to methods)

**Comments**:
- Comments explain WHY, not WHAT
- Focus on current behavior, not history
- Delete outdated comments immediately
- Prefer self-documenting code over comments

### Python

- Follow PEP 20 – The Zen of Python (https://peps.python.org/pep-0020)
- Follow PEP 8 – Style Guide for Python Code (https://peps.python.org/pep-0008)

#### Docstrings

Use **Sphinx/reStructuredText style** for all docstrings:

```python
"""Description of the function.

:param name: Description of the argument.
:return: Description of the return value.
"""
```

### Testing Guidelines

**Consistency Rule**: Each package uses either unittest or pytest style - never mix them.

**Before adding tests**:
1. Check existing tests in the package (`sources/<package>/src/*/tests/`)
2. Use the same style and patterns as existing tests

**unittest/zope.testlayer style** (most common):
- Inherit from `unittest.TestCase`
- Use `setUp()` and `tearDown()` for test-level setup
- Use zope testlayers for integration/functional fixtures
- Test methods: `test_<descriptive_name>`
- Use unittest assertions: `assertEqual()`, `assertTrue()`, `assertRaises()`

**pytest style** (some packages):
- Use pytest fixtures (`@pytest.fixture`)
- Use `assert` statements directly
- Use pytest marks and parametrize when needed
- Test functions: `test_<descriptive_name>`

**General**:
- Write tests that document behavior, not implementation
- Test names should describe the expected behavior
- One logical assertion per test when possible
